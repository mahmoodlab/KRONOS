{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tissue Phenotyping using KRONOS Embedding\n",
    "KRONOS embedding can be used to cluster tissue into different regions/phenotypes which can then be used for patient stratification or therapy response prediction.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "To follow this tutorial, ensure you have the following data prepared:\n",
    "\n",
    "1. **Multiplex Images**: TIFF images with multiple markers (e.g., DAPI, CD markers, etc.).\n",
    "2. **Marker Metadata**: A CSV file containing the following columns:\n",
    "    - `channel_id`: Identifier for the image channel.\n",
    "    - `marker_name`: Name of the marker (e.g., DAPI, CD20).\n",
    "    - `marker_id`: Unique ID for the marker.\n",
    "    - `marker_mean`: Mean intensity value for normalization.\n",
    "    - `marker_std`: Standard deviation for normalization.\n",
    "\n",
    "\n",
    "**Notes**:<br> \n",
    "Refer to the **[How-to-get-marker-metadata-file](https://github.com/mahmoodlab/KRONOS/blob/main/tutorials/1%20-%20How-to-get-marker-metadat-file.ipynb)** tutorial to generate the metadata file for your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Packages\n",
    "\n",
    "We begin by importing the necessary libraries and modules for the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io as skio\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "from kronos import create_model_from_pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the root directory for the project\n",
    "project_dir = \"/path/to/project/directory/\"  # Replace with your actual project directory\n",
    "\n",
    "# Configuration dictionary containing all parameters for the pipeline\n",
    "config = {\n",
    "    \"multiplex_image_path\": f\"{project_dir}/dataset/multiplex_images/image_01.tiff\",\n",
    "    \"marker_info_with_metadata_csv_path\": f\"{project_dir}/dataset/marker_info_with_metadata.csv\", # Path to the marker metadata CSV file\n",
    "    \"results_dir\": f\"{project_dir}/results/\",\n",
    "    \n",
    "    # Model-related parameters\n",
    "    \"checkpoint_path\": \"hf_hub:MahmoodLab/kronos\",  # Path to the pre-trained model checkpoint (local or Hugging Face Hub)\n",
    "    \"hf_auth_token\": None,  # Authentication token for Hugging Face Hub (if checkpoint is from the Hub)\n",
    "    \"cache_dir\": f\"{project_dir}/models/\",  # Directory to cache KRONOS model if downloading from Hugging Face Hub\n",
    "    \"model_type\": \"vits16\",  # Type of pre-trained model to use (e.g., vits16)\n",
    "    \"token_overlap\": False,  # Whether to use token overlap during feature extraction\n",
    "    \n",
    "    \"patch_size\": 64, # Size of the patches to be extracted from the multiplex image\n",
    "    \"stride_size\" : 32, # Stride size for the sliding window approach \n",
    "    \"batch_size\": 32, # Batch size for processing patches through the model\n",
    "    \"n_clusters\": 20, # Number of clusters for clustering\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = skio.imread(config[\"multiplex_image_path\"])\n",
    "img = img/np.iinfo(img.dtype).max\n",
    "\n",
    "print(\"Image shape (n_markers, height, width): \", img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Marker Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_metadata = pd.read_csv(config[\"marker_info_with_metadata_csv_path\"])\n",
    "marker_metadata.set_index(\"marker_name\", inplace=True)\n",
    "display(marker_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Markers of Interest for Tissue Phenotyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_names = ['DAPI-01', 'CD11B', 'CD11C', 'CD15', 'CD163', 'CD20', 'CD206', 'CD30', 'CD31', 'CD4', 'CD56', 'CD68', 'CD7', 'CD8', 'CYTOKERITIN', 'FOXP3', 'MCT', 'PODOPLANIN']\n",
    "        \n",
    "marker_img = img[[marker_metadata.loc[marker_name][\"channel_id\"].astype(int) for marker_name in marker_names]]\n",
    "marker_mean = np.array([marker_metadata.loc[marker_name][\"marker_mean\"] for marker_name in marker_names])\n",
    "marker_std = np.array([marker_metadata.loc[marker_name][\"marker_std\"] for marker_name in marker_names])\n",
    "marker_ids = [marker_metadata.loc[marker_name][\"marker_id\"].astype(np.int64) for marker_name in marker_names]\n",
    "print(\"Image shape (n_markers, height, width): \", marker_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.max(marker_img) > 1:\n",
    "    marker_img = marker_img / np.iinfo(marker_img.dtype).max # converting image from 0-65535 to 0-1\n",
    "\n",
    "# normalizing the image using markser specific mean and std values\n",
    "marker_img = (marker_img - marker_mean[:, None, None]) / marker_std[:, None, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load KRONOS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the KRONOS library to create a model from a pre-trained checkpoint\n",
    "model, precision, embedding_dim = create_model_from_pretrained(\n",
    "    checkpoint_path=config[\"checkpoint_path\"],  # Path to the model checkpoint\n",
    "    cfg_path=None,  # Configuration path (not used here)\n",
    "    hf_auth_token=config[\"hf_auth_token\"],  # Hugging Face authentication token\n",
    "    cache_dir=config[\"cache_dir\"],  # Directory to cache the model\n",
    "    cfg={\n",
    "        \"model_type\": config[\"model_type\"],  # Type of model (e.g., ViT-S16)\n",
    "        \"token_overlap\": config[\"token_overlap\"]  # Whether to use token overlap\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = []\n",
    "coords = []\n",
    "patch_size = config[\"patch_size\"]\n",
    "stride_size = config[\"stride_size\"]\n",
    "for i in range(0, marker_img.shape[1] - patch_size + 1, stride_size):\n",
    "    for j in range(0, marker_img.shape[2] - patch_size + 1, stride_size):\n",
    "        patches.append(marker_img[:, i:i+patch_size, j:j+patch_size])\n",
    "        coords.append((i, j))\n",
    "print(\"Number of patches: \", len(patches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = config[\"batch_size\"]\n",
    "patch_features_list = []\n",
    "marker_features_list = []\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "model.eval()\n",
    "for i in range(0, len(patches), batch_size):\n",
    "    print(f\"Processing batch {i//batch_size+1}/{len(patches)//batch_size+1}\", end=\"\\r\") \n",
    "    if (i+batch_size) > len(patches):\n",
    "        batch = patches[i:]\n",
    "    else:\n",
    "        batch = patches[i:i+batch_size]\n",
    "    batch = torch.tensor(np.array(batch), device=device, dtype=torch.float32)\n",
    "    batch_marker_ids = [torch.tensor(marker_ids, device=device) for _ in range(batch.shape[0])]\n",
    "    with torch.no_grad():\n",
    "        patch_features, marker_features, _  = model(batch, marker_ids=batch_marker_ids)\n",
    "    patch_features_list.extend(patch_features.cpu().numpy())\n",
    "    marker_features_list.extend(marker_features.cpu().numpy())\n",
    "patch_features = np.array(patch_features_list)\n",
    "marker_features = np.array(marker_features_list)\n",
    "print(\"Patch features shape: \", patch_features.shape)\n",
    "print(\"Marker features shape: \", marker_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phenotyping\n",
    "While any appropriate clustering method for tissue phenotyping can be used, here we used KMeans as it is computationally efficient and performs robustly on Kronos embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=config[\"n_clusters\"], random_state=0)\n",
    "\n",
    "labels = kmeans.fit_predict(marker_features.reshape(marker_features.shape[0], -1))\n",
    "cluster_map = np.zeros((marker_img.shape[1], marker_img.shape[2]), dtype=np.uint8)\n",
    "for i, (x, y) in enumerate(coords):\n",
    "    cluster_map[x:x+patch_size, y:y+patch_size] = labels[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Clustering Results along with Multiplex Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rgb_image(multiplex_image, colors):\n",
    "    multiplex_image = multiplex_image.astype(np.float32)\n",
    "    # Normalize each channel individually\n",
    "    for i in range(multiplex_image.shape[-1]):\n",
    "        min_val, max_val = multiplex_image[..., i].min(), multiplex_image[..., i].max()\n",
    "        if max_val > min_val:\n",
    "            multiplex_image[..., i] = (multiplex_image[..., i] - min_val) / (max_val - min_val)\n",
    "\n",
    "    # Compute the weighted sum of colors\n",
    "    multiplex_image = np.tensordot(multiplex_image*2, colors, axes=([2], [0]))\n",
    "    multiplex_image = np.clip(multiplex_image, 0, 255).astype(np.uint8)\n",
    "    return multiplex_image\n",
    "\n",
    "colors = np.array([\n",
    "    [0, 0, 255],    # Blue\n",
    "    [255, 0, 0],    # Red \n",
    "    [0, 255, 0],    # Green \n",
    "    [255, 255, 0],  # Yellow \n",
    "    [255, 0, 255],  # Magenta \n",
    "    [0, 255, 255],  # Cyan \n",
    "], dtype=np.float32)\n",
    "color_list = ['Blue', 'Red', 'Green', 'Yellow', 'Magenta', 'Cyan']\n",
    "marker_set_1 = ['DAPI-01', 'CD11B', 'CD11C', 'CD15', 'CD163', 'CD20']\n",
    "marker_set_2 = ['DAPI-01', 'CD206', 'CD30', 'CD31', 'CD4', 'CD56']\n",
    "marker_set_3 = ['DAPI-01', 'CD7', 'CD8', 'CYTOKERITIN', 'FOXP3', 'PODOPLANIN']\n",
    "\n",
    "multiplex_image_1 = np.stack([img[marker_metadata.loc[marker_name][\"channel_id\"].astype(int), :, :] for marker_name in marker_set_1], axis=-1)\n",
    "multiplex_image_2 = np.stack([img[marker_metadata.loc[marker_name][\"channel_id\"].astype(int), :, :] for marker_name in marker_set_2], axis=-1)\n",
    "multiplex_image_3 = np.stack([img[marker_metadata.loc[marker_name][\"channel_id\"].astype(int), :, :] for marker_name in marker_set_3], axis=-1)\n",
    "\n",
    "multiplex_image_1 = get_rgb_image(multiplex_image_1, colors)\n",
    "multiplex_image_2 = get_rgb_image(multiplex_image_2, colors)\n",
    "multiplex_image_3 = get_rgb_image(multiplex_image_3, colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "ax[0, 0].set_title(\", \".join([color_name+\":\"+marker_name for color_name, marker_name in zip(color_list, marker_set_1)]), fontsize=8)\n",
    "ax[0, 0].imshow(multiplex_image_1)\n",
    "ax[0, 0].axis('off')\n",
    "ax[0, 1].set_title(\", \".join([color_name+\":\"+marker_name for color_name, marker_name in zip(color_list, marker_set_2)]), fontsize=8)\n",
    "ax[0, 1].imshow(multiplex_image_2)\n",
    "ax[0, 1].axis('off')\n",
    "ax[1, 0].set_title(\", \".join([color_name+\":\"+marker_name for color_name, marker_name in zip(color_list, marker_set_3)]), fontsize=7)\n",
    "ax[1, 0].imshow(multiplex_image_3)\n",
    "ax[1, 0].axis('off')\n",
    "ax[1, 1].set_title(\"Cluster Map\")\n",
    "ax[1, 1].imshow(cluster_map, cmap='tab20')\n",
    "ax[1, 1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kronos_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
